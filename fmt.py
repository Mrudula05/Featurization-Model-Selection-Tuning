# -*- coding: utf-8 -*-
"""FMT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BAyAHy93jvbby5RTQrHNe3PbIhKsgtFh

**Project Objective:  Build a classifier to predict the Pass/Fail yield of a particular process entity and analyse whether all the 
features are required to build the model or not.**

# 1. Import and explore the data

# New Section
"""

import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import GridSearchCV
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import Lasso
from sklearn.svm import OneClassSVM
import os

s_data = pd.read_csv('signal-data.csv')
print(s_data.shape)

s_data.info()

s_data.describe()

s_data.head()

#check for null values

s_data.isnull().any().any()

#Absence of data means there is no data recorded for partiar instance.
#So its not good to replace null values with mean or median.
#We can replace Nan values with 0.
s_data = s_data.replace(np.NaN, 0)

#Check again if we have any null values
s_data.isnull().any()

"""# **Data analysis & visualisation** """

#pass and fail column comes under categorical data.so check unique values from that column.
unique_values = s_data['Pass/Fail'].unique()
targets = [s_data.loc[s_data['Pass/Fail'] == val] for val in unique_values]

#plot histogram for sensor nodes
fig = plt.figure(figsize=(20,20))

plt.subplot(2, 2, 1)
for target in targets:
    sns.distplot(target['1'], hist=True, rug=True)
plt.title('First Sensor', fontsize = 20)

plt.subplot(2, 2, 2)
for target in targets:
    sns.distplot(target['2'], hist=True, rug=True)
plt.title('Second Sensor', fontsize = 20)

plt.subplot(2, 2, 3)
for target in targets:
    sns.distplot(target['3'], hist=True, rug=True)
plt.title('Third Sensor', fontsize = 20)

plt.subplot(2, 2, 4)
for target in targets:
    sns.distplot(target['4'], hist=True, rug=True)
plt.title('Fourth Sensor', fontsize = 20)

#sns.add_legend()
#plt.legend()
fig.legend(labels=['Pass','Fail'])
plt.show()

#bar plot
s_data['Pass/Fail'].value_counts().plot(kind="bar").colors='red';

labels = ['Pass', 'Fail']
size = s_data['Pass/Fail'].value_counts()
colors = ['green', 'red']
explode = [0, 0.1]

# heatmap to find out correlation

plt.rcParams['figure.figsize'] = (18, 18)
sns.heatmap(s_data.corr())
plt.title('Correlation for the Data', fontsize = 20)

"""# **Data Cleaning/Preprocessing**"""

#Remove the highly collinear features from data
def remove_collinear_features(x, threshold):
  
    # Calculate the correlation matrix
    corr_matrix = x.corr()
    iters = range(len(corr_matrix.columns) - 1)
    drop_cols = []

    # Iterate through the correlation matrix and compare correlations
    for i in iters:
        for j in range(i+1):
            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]
            col = item.columns
            row = item.index
            val = abs(item.values)

            if val >= threshold:
                
                print(col.values[0], "|", row.values[0], "|", round(val[0][0], 2))
                drop_cols.append(col.values[0])

    
    drops = set(drop_cols)
    x = x.drop(columns=drops)

    return x

#Remove columns having more than 70% correlation

s_data = remove_collinear_features(s_data,0.70)

# Deleting the unnecessary columns
s_data = s_data.drop(columns = ['Time'], axis = 1)

# checking the shape of the data after deleting a column
s_data.shape

s_data.head()

# separating the dependent and independent data

x = s_data.iloc[:,:307]
y = s_data["Pass/Fail"]
print("x:", x.shape)
print("y:", y.shape)

# splitting them into train test and split

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1)

# gettiing the shapes
print("shape of x_train: ", x_train.shape)
print("shape of x_test: ", x_test.shape)
print("shape of y_train: ", y_train.shape)
print("shape of y_test: ", y_test.shape)

# standardization

from sklearn.preprocessing import StandardScaler

# creatE a standard scaler
sc = StandardScaler()

# fitting independent data to the model
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

"""# **XGBoost Algorithm (Normal data)**"""

model = XGBClassifier(random_state=1)
model.fit(x_train, y_train)
y_pred = model.predict(x_test)

cm = confusion_matrix(y_test, y_pred)
plt.rcParams['figure.figsize'] = (5, 5)
sns.set(style = 'white', font_scale = 1.4)
sns.heatmap(cm, annot = True)

print("Accuracy: ", model.score(x_test,y_test)*100)

"""In the failure class we have only 1 observation classified correctly for XGBoost but still has 100% accuracy as we predicted correctly on the observations that passed

# **Random Forest Classifier (Normal Data)**
"""

model = RandomForestClassifier(n_estimators=100, random_state=1,verbose=0 )
model.fit(x_train, y_train)
y_pred = model.predict(x_test)

cm = confusion_matrix(y_test, y_pred)
plt.rcParams['figure.figsize'] = (5, 5)
sns.set(style = 'dark', font_scale = 1.4)
sns.heatmap(cm, annot = True, annot_kws = {"size": 15})

print("Accuracy: ", model.score(x_test,y_test)*100)

"""In the failure class we have no observation classified correctly for Random Forest but still has 99.36% accuracy.

# **Logistic Regression (Normal Data)**
"""

lr = LogisticRegression(random_state=1)
lr.fit(x_train, y_train) 
y_pred = lr.predict(x_test)

cm = confusion_matrix(y_test, y_pred)
plt.rcParams['figure.figsize'] = (5, 5)
sns.set(style = 'dark', font_scale = 1.4)
sns.heatmap(cm, annot = True, annot_kws = {"size": 15})

print("Accuracy: ", lr.score(x_test,y_test)*100)

"""In the failure class we have 4 observation classified correctly for logistic regression and 100% accuracy as we predicted correctly on the observations that passed. So even though this model has lesser accuracy it is preferable over previous models as at least it is classifying more observations in the failure class correctly

# **Lasso (Normal Data)**
"""

lasso = Lasso(alpha=0.1,random_state=1)
lasso.fit(x_train,y_train)
#print ("Lasso model:", (lasso.coef_))

y_pred = lasso.predict(x_test)

#Convert the sign of the predicted values as the classifier
y_pred2 = np.sign(y_pred)

print("Accuracy: ", lasso.score(x_test,y_test)*100)

cm = confusion_matrix(y_test, y_pred2)
sns.heatmap(cm, annot = True, cmap = 'rainbow')

"""# UnderSampling of the Dataset"""

# Under Sampling - Check how many failure observations are there
# We have 104 such observations

failed_tests = np.array(s_data[s_data['Pass/Fail'] == 1].index)
no_failed_tests = len(failed_tests)

print(no_failed_tests)

# Check how many pass observations are there
# We have 1,463 such observations

normal_indices = s_data[s_data['Pass/Fail'] == -1]
no_normal_indices = len(normal_indices)

print(no_normal_indices)

# Get 104 random observations from the pass class as well

random_normal_indices = np.random.choice(no_normal_indices, size = no_failed_tests, replace = True)
random_normal_indices = np.array(random_normal_indices)

print(len(random_normal_indices))

#Getting a 50-50 representation from both pass and fail classes
under_sample = np.concatenate([failed_tests, random_normal_indices])
print(len(under_sample))

# creating the undersample data

undersample_data = s_data.iloc[under_sample, :]

# splitting the undersample dataset into x and y sets

x = undersample_data.iloc[:, undersample_data.columns != 'Pass/Fail'] 
y = undersample_data.iloc[:, undersample_data.columns == 'Pass/Fail']

print(x.shape)
print(y.shape)

from sklearn.model_selection import train_test_split

x_train_us, x_test_us, y_train_us, y_test_us = train_test_split(x, y, test_size = 0.3, random_state = 1)

print(x_train_us.shape)
print(y_train_us.shape)
print(x_test_us.shape)
print(y_test_us.shape)

sc = StandardScaler()
x_train_us = sc.fit_transform(x_train_us)
x_test_us = sc.transform(x_test_us)

"""# **Xg-Boost Classifier (Undersampling)**"""

model = XGBClassifier(random_state=1)

model.fit(x_train_us, y_train_us)

y_pred = model.predict(x_test_us)

cm = confusion_matrix(y_test_us, y_pred)


plt.rcParams['figure.figsize'] = (5, 5)
sns.set(style = 'dark', font_scale = 1.4)
sns.heatmap(cm, annot = True, annot_kws = {"size": 15})

# It is able to predict 26 defected semiconductors among 35 Semi-Conductors

"""# **Grid Search - XG Boost (Undersampling)**"""

# Applying Grid Search CV to find the best model with the best parameters



parameters = [{'max_depth' : [1, 2, 3, 4, 5, 6],
              'cv' : [2,4,6,8,10],
              'random_state' : [1]}]

grid_search = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'accuracy',  n_jobs = -1)

grid_search = grid_search.fit(x_train_us, y_train_us)
best_accuracy = grid_search.best_score_
best_parameters = grid_search.best_params_

print("Best Accuracy: ", best_accuracy*100)
print("Best Parameter: ", best_parameters)

Parameter:  {'cv': 2, 'max_depth': 3, 'random_state': 1}
weights = (y == 0).sum()/(1.0*(y == -1).sum())
model = XGBClassifier(max_depth = 1, scale_pos_weights = weights, n_jobs = 4,random_state=1,cv=2)

model.fit(x_train_us, y_train_us)

y_pred = model.predict(x_test_us)

"""# **Confusion matrix XG Boost - Grid Search (Undersample)**"""

cm = confusion_matrix(y_test_us, y_pred)


plt.rcParams['figure.figsize'] = (5, 5)
sns.set(style = 'dark', font_scale = 1.4)
sns.heatmap(cm, annot = True, annot_kws = {"size": 15})

# plotting the feature importances

colors = plt.cm.spring(np.linspace(0, 1, 9))
xgb.plot_importance(model, height = 1, color = colors, grid = True, importance_type = 'cover', show_values = False)

plt.rcParams['figure.figsize'] = (200, 200)
plt.xlabel('The F-Score for each features')
plt.ylabel('Importances')
plt.show()

"""# **Over-Sampling with SMOTE**"""

x_resample, y_resample  = SMOTE(random_state=1).fit_sample(x, y.values.ravel())

print(x_resample.shape)
print(y_resample.shape)

x_train_os, x_test_os, y_train_os, y_test_os = train_test_split(x, y, test_size = 0.3, random_state = 1)

print(x_train_os.shape)
print(y_train_os.shape)
print(x_test_os.shape)
print(y_test_os.shape)

sc = StandardScaler()
x_train_os = sc.fit_transform(x_train_os)
x_test_os = sc.transform(x_test_os)

"""# **Xg-Boost Classifier - Grid Search (Oversampling)**"""

import xgboost as xgb
from xgboost.sklearn import XGBClassifier

model = XGBClassifier(random_state=1)

model.fit(x_train_os, y_train_os)

y_pred = model.predict(x_test_os)

# Applying Grid Search CV to find the best model with the best parameters

from sklearn.model_selection import GridSearchCV

# making a parameters list
parameters = [{'max_depth' : [1, 2, 3, 4, 5, 6],
              'cv' : [2,4,6,8,10],
              'random_state' : [1]}]

# making a grid search model
grid_search = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'accuracy', n_jobs = -1)
grid_search = grid_search.fit(x_train_os, y_train_os)

# getting the results
best_accuracy = grid_search.best_score_
best_parameters = grid_search.best_params_

print("Best Accuracy: ", best_accuracy)
print("Best Parameter: ", best_parameters)

weights = (y == 0).sum()/(1.0*(y == -1).sum())
model = XGBClassifier(max_depth = 1, scale_pos_weights = weights, n_jobs = 4,random_state=1,cv=2)

model.fit(x_train_os, y_train_os)

y_pred = model.predict(x_test_os)

"""# **Random Forest (Oversampling)**"""

model = RandomForestClassifier(n_estimators=100, random_state=1,verbose=0 )
model.fit(x_train_os, y_train_os)
#scores_prediction = model.decision_function(x_train)
y_pred = model.predict(x_test_os)
print("Accuracy: ", model.score(x_test_os,y_test_os)*100)

"""# **Confusion Matrix after OverSampling with XgBoost**"""

cm = confusion_matrix(y_test_os, y_pred)


plt.rcParams['figure.figsize'] = (5, 5)
sns.set(style = 'dark', font_scale = 1.4)
sns.heatmap(cm, annot = True, annot_kws = {"size": 15}, cmap = 'spring')

"""# **Random Forest - (Oversampled) - Confusion Matrix**"""

# printing the confusion matrix
cm = confusion_matrix(y_test_os, y_pred)
sns.heatmap(cm, annot = True, cmap = 'rainbow')

"""# **Logistic regression - (Oversampled)**"""

lr = LogisticRegression(random_state=1)
lr.fit(x_train_os, y_train_os) 
y_pred = lr.predict(x_test_os)

print("Accuracy: ", lr.score(x_test_os,y_test_os)*100)

"""# **Logistic regression (Oversampled) - Confusion matrix**"""

cm = confusion_matrix(y_test_os, y_pred)
sns.heatmap(cm, annot = True, cmap = 'rainbow')

"""# **Random Forest - (Undersampled)**"""

model = RandomForestClassifier(n_estimators=100, random_state=1,verbose=0 )
model.fit(x_train_us, y_train_us)
#scores_prediction = model.decision_function(x_train)
y_pred = model.predict(x_test_us)

"""# **Confusion Matrix for Random Forest (Undersampled)**"""

# evaluating the model

# printing the confusion matrix
cm = confusion_matrix(y_test_us, y_pred)
sns.heatmap(cm, annot = True, cmap = 'rainbow')

"""# **Using Lasso (Undersampled)**"""

lasso = Lasso(alpha=0.1,random_state=1)
lasso.fit(x_train_us,y_train_us)
print ("Lasso model:", (lasso.coef_))

y_pred = lasso.predict(x_test_us)

print(y_pred)

print(y_test_us)

#Convert the sign of the predicted values as the classifier
y_pred2 = np.sign(y_pred)

"""# **Confusion matrix for Lasso (Undersampled)**"""

cm = confusion_matrix(y_test_us, y_pred2)
sns.heatmap(cm, annot = True, cmap = 'rainbow')

print("Accuracy: ", lasso.score(x_test_us,y_test_us)*100)

"""# **Logistic Regression (Undersampled)**"""

lr = LogisticRegression(random_state=1)
lr.fit(x_train_us, y_train_us)

y_pred = lr.predict(x_test_us)
print(y_pred)

"""# **Confusion matrix for Logistic Regression (Undersampled)**"""

cm = confusion_matrix(y_test_us, y_pred)
sns.heatmap(cm, annot = True, cmap = 'rainbow')

"""# **Confusion Matrix for One Class SVM**"""

#evaluating the model
# printing the confusion matrix
cm = confusion_matrix(y_test_us, y_pred)
sns.heatmap(cm ,annot = True, cmap = 'winter')

"""# **PCA for demensionality reduction**"""

#Scaling the data before applying PCA
from scipy.stats import zscore
s_data_new=s_data.iloc[:,:306].apply(zscore)
s_data_new.head()

s_data_new.isnull().any().any()

s_data_new = s_data_new.replace(np.NaN, 0)

s_data_new.isnull().any().any()

# separating the dependent and independent data

x = s_data_new.iloc[:,:306]
y = s_data["Pass/Fail"]

# getting the shapes of new data sets x and y
print("shape of x:", x.shape)
print("shape of y:", y.shape)

cov_matrix = np.cov(x.T)
print('Covariance Matrix \n%s', cov_matrix)

eig_vals, eig_vecs = np.linalg.eig(cov_matrix)
print('Eigen Vectors \n%s', eig_vecs)
print('\n Eigen Values \n%s', eig_vals)

tot = sum(eig_vals)
var_exp = [( i /tot ) * 100 for i in sorted(eig_vals, reverse=True)]
cum_var_exp = np.cumsum(var_exp)
print("Cumulative Variance Explained", cum_var_exp)

plt.plot(var_exp)

plt.figure(figsize=(10 , 5))
plt.bar(range(1, eig_vals.size + 1), var_exp, alpha = 0.5, align = 'center', label = 'Individual explained variance')
plt.step(range(1, eig_vals.size + 1), cum_var_exp, where='mid', label = 'Cumulative explained variance')
plt.ylabel('Explained Variance Ratio')
plt.xlabel('Principal Components')
plt.legend(loc = 'best')
plt.tight_layout()
plt.show()

len(cum_var_exp)

from sklearn.decomposition import PCA
pca = PCA(n_components=130)
data_reduced = pca.fit_transform(x)
data_reduced.transpose()

pca.components_

df_comp = pd.DataFrame(pca.components_,columns=list(x))
df_comp.head()

plt.figure(figsize=(12,6))
sns.heatmap(df_comp,cmap='plasma',)

data_reduced.shape

df_red2 = pd.DataFrame(data_reduced)
df_red2.head()

df_red3 = df_red2.copy()
df_red4 = df_red3
df_red4["Pass/Fail"] = s_data["Pass/Fail"]

df_red4.head()

df_red4.shape

df_red4.boxplot(column = [df_red4.columns[0],
                          df_red4.columns[1],
                          df_red4.columns[2],
                          df_red4.columns[3], 
                          df_red4.columns[4],
                          df_red4.columns[5],
                         ]
                          , by = 'Pass/Fail', figsize=(20,20))

pd_data = df_red4.copy()



from scipy import stats

#Define a function to remove outliers on max side
def outlier_removal_max(var):
    var = np.where(var > var.quantile(0.75)+ stats.iqr(var),var.quantile(0.50),var)
    return var

#Define a function to remove outliers on min side
def outlier_removal_min(var):
    var = np.where(var < var.quantile(0.25) - stats.iqr(var),var.quantile(0.50),var)
    return var

#Loop over the columns and remove the outliers on min and max side
for column in pd_data:
    pd_data[column] = outlier_removal_max(pd_data[column])
    pd_data[column] = outlier_removal_min(pd_data[column])

pd_data.boxplot( column =[df_red4.columns[0],
                          df_red4.columns[1],
                          df_red4.columns[2],
                          df_red4.columns[3], 
                          df_red4.columns[4],
                          df_red4.columns[5],
                         ],by = 'Pass/Fail', figsize=(20,20))

x = df_red4.iloc[:, df_red4.columns != 'Pass/Fail'] 
y = df_red4.iloc[:, df_red4.columns == 'Pass/Fail']

# getting the shapes of new data sets x and y
print("shape of x:", x.shape)
print("shape of y:", y.shape)

failed_tests = np.array(df_red4[df_red4['Pass/Fail'] == 1].index)
no_failed_tests = len(failed_tests)

print(no_failed_tests)

normal_indices = df_red4[df_red4['Pass/Fail'] == -1]
no_normal_indices = len(normal_indices)

print(no_normal_indices)

random_normal_indices = np.random.choice(no_normal_indices, size = no_failed_tests, replace = True)
random_normal_indices = np.array(random_normal_indices)

print(len(random_normal_indices))

under_sample = np.concatenate([failed_tests, random_normal_indices])
print(len(under_sample))

from sklearn.model_selection import train_test_split

x_train_us, x_test_us, y_train_us, y_test_us = train_test_split(x, y, test_size = 0.3, random_state = 1)

print(x_train_us.shape)
print(y_train_us.shape)
print(x_test_us.shape)
print(y_test_us.shape)

sc = StandardScaler()
x_train_us = sc.fit_transform(x_train_us)
x_test_us = sc.transform(x_test_us)
print(x_train_us)
print(x_test_us)

"""# **Conclusion and Observations**

1.We perform all the oversampling, undersampling and normal data techniques.
2. We used We have tried multiple models Logistic Regression, Random Forest, XG Boost (with and without Grid Search),OneClassSVM for differet claasses.
3. Also we have calculate confusion matrix for each model and Calculate Accuracy for the same model.
4. We did Z score scaling on both the datasets and took PCA with n_components as However PCA did not improve either accuracy or recall probably as we were loosing information due to dropping dimensions.
"""